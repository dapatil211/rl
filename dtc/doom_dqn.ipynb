{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools as it\n",
    "import pickle\n",
    "from time import time, sleep\n",
    "\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from skimage import transform, io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-learning settings\n",
    "learning_rate = 0.00025\n",
    "# learning_rate = 0.0001\n",
    "discount_factor = 0.99\n",
    "epochs = 20\n",
    "learning_steps_per_epoch = 2000\n",
    "replay_memory_size = 10000\n",
    "\n",
    "# NN learning settings\n",
    "batch_size = 64\n",
    "\n",
    "# Training regime\n",
    "test_episodes_per_epoch = 100\n",
    "\n",
    "# Other parameters\n",
    "frame_repeat = 12\n",
    "resolution = (30, 45)\n",
    "episodes_to_watch = 10\n",
    "\n",
    "model_savefile = \"/tmp/weights.dump\"\n",
    "# Configuration file path\n",
    "config_file_path = '../ViZDoom/scenarios/defend_the_center.cfg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vizdoom(config_file_path):\n",
    "    print(\"Initializing doom...\")\n",
    "    game = DoomGame()\n",
    "    game.load_config(config_file_path)\n",
    "    game.set_window_visible(False)\n",
    "    game.set_mode(Mode.PLAYER)\n",
    "    game.set_screen_format(ScreenFormat.GRAY8)\n",
    "    game.set_screen_resolution(ScreenResolution.RES_640X480)\n",
    "    game.init()\n",
    "    print(\"Doom initialized.\")\n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom...\n",
      "Doom initialized.\n"
     ]
    }
   ],
   "source": [
    "game = initialize_vizdoom(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = transform.resize(image, resolution)\n",
    "    image = np.ascontiguousarray(image, dtype=np.float32)\n",
    "    image = torch.from_numpy(image)\n",
    "    return image\n",
    "\n",
    "def get_current_state():\n",
    "    return preprocess(game.get_state().screen_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [list(a) for a in it.product([0, 1], repeat=game.get_available_buttons_size())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay:\n",
    "    curIndex = 0\n",
    "    size = 0\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.replay = []\n",
    "    def add(self, s1, s2, action, reward):\n",
    "        if not s2:\n",
    "            s2 = torch.zeros(s1.size())\n",
    "        if self.size == self.capacity:\n",
    "            self.replay[self.curIndex] = (s1, s2, action, reward)\n",
    "        else:\n",
    "            self.replay.append((s1, s2, action, reward))\n",
    "            self.size = min(self.size + 1, self.capacity)\n",
    "        self.curIndex = (self.curIndex + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.replay, batch_size)\n",
    "replay = Replay(replay_memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=6, stride=3)\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(192, 128)\n",
    "        self.fc2 = nn.Linear(128, len(actions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "dqn = DQN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = nn.MSELoss()\n",
    "optimizer = optim.SGD(dqn.parameters(), lr=learning_rate)\n",
    "\n",
    "def get_q(input):\n",
    "    input = Variable(input)\n",
    "    return dqn(input)\n",
    "\n",
    "def get_action(input):\n",
    "    qs = get_q(input)\n",
    "    val, ind = torch.max(qs, 1)\n",
    "    return ind.data.numpy()[0]\n",
    "\n",
    "def learn_replay():\n",
    "    if batch_size <= replay.size:\n",
    "        sample = zip(*replay.sample(batch_size))\n",
    "        s1, s2, action, reward = sample\n",
    "        \n",
    "        s1 = torch.stack(s1)\n",
    "        s1 = s1.view(s1.size()[0], 1, s1.size()[1], s1.size()[2])\n",
    "        \n",
    "        action = np.array(action)\n",
    "        q1 = get_q(s1)\n",
    "        q1 = q1.data.numpy()[np.arange(action.size), action]\n",
    "        s2 = torch.stack(s2)\n",
    "        s2 = s2.view(s2.size()[0], 1, s2.size()[1], s2.size()[2])\n",
    "        q2 = get_q(s2).data.numpy()\n",
    "        q2 = np.max(q2, 1)\n",
    "        #q_func = np.vectorize(lambda s:np.max(get_q(s.view(1, 1, resolution[0], resolution[1]))) if s else 0)\n",
    "        #q2 = q_func(s2)\n",
    "        \n",
    "        y = reward + discount_factor * q2\n",
    "        \n",
    "        q1 = Variable(torch.from_numpy(q1), requires_grad=True)\n",
    "        y = Variable(torch.from_numpy(y).float())\n",
    "        loss = mse(q1, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(eps):\n",
    "    action = 0\n",
    "    s1 = get_current_state()\n",
    "    if random.random() < eps:\n",
    "        action = random.randint(0, len(actions)-1)\n",
    "    else:\n",
    "        action = get_action(s1.view(1, 1, s1.size()[0], s1.size()[1]))\n",
    "    reward = game.make_action(actions[action])\n",
    "    s2 = None if game.is_episode_finished else get_current_state()\n",
    "    replay.add(s1, s2, action, reward)\n",
    "    learn_replay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 EPOCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshan/doom/doom/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "1 EPOCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshan/doom/doom/lib/python2.7/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type DQN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "2 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "3 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "4 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "5 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "6 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "7 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "8 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "9 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "10 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "11 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "12 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "13 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "14 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "15 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "16 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "17 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "18 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "19 EPOCH\n",
      "200 of 2000\n",
      "400 of 2000\n",
      "600 of 2000\n",
      "800 of 2000\n",
      "1000 of 2000\n",
      "1200 of 2000\n",
      "1400 of 2000\n",
      "1600 of 2000\n",
      "1800 of 2000\n",
      "2000 of 2000\n",
      "Epoch score: 0\n",
      "======================================\n",
      "Training finished. It's time to watch!\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "EPS_START = .95\n",
    "EPS_END = .1\n",
    "EPS_CONST = NUM_EPOCHS * .1\n",
    "EPS_DECAY = NUM_EPOCHS * .70\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print \"%d EPOCH\" % i\n",
    "    learning_steps = 0\n",
    "    num_episodes = 0\n",
    "    epsilon = 0\n",
    "    if i <= EPS_CONST:\n",
    "        epsilon = EPS_START\n",
    "    elif i <= EPS_DECAY:\n",
    "        epsilon = EPS_START - (i - EPS_CONST) / (EPS_DECAY - EPS_CONST) * (EPS_START - EPS_END)\n",
    "    else:\n",
    "        epsilon = EPS_END\n",
    "    scores = []\n",
    "    while learning_steps < learning_steps_per_epoch:\n",
    "        if(game.is_episode_finished() or num_episodes == 0):\n",
    "            scores.append(game.get_total_reward())\n",
    "            game.new_episode()\n",
    "            num_episodes += 1\n",
    "        learn(epsilon)\n",
    "        learning_steps += 1\n",
    "        if learning_steps % 200 == 0:\n",
    "            print \"%d of %d\" % (learning_steps, learning_steps_per_epoch)\n",
    "    print(\"Epoch score: %d\" % np.mean(scores))\n",
    "    torch.save(dqn, model_savefile)\n",
    "\n",
    "game.close()\n",
    "print(\"======================================\")\n",
    "print(\"Training finished. It's time to watch!\")\n",
    "\n",
    "# Reinitialize the game with window visible\n",
    "game.set_window_visible(True)\n",
    "game.set_mode(Mode.ASYNC_PLAYER)\n",
    "game.init()\n",
    "\n",
    "for _ in range(episodes_to_watch):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = get_current_state()\n",
    "        state = state.view(1, 1, resolution[0], resolution[1])\n",
    "        best_action_index = get_action(state)\n",
    "\n",
    "        # Instead of make_action(a, frame_repeat) in order to make the animation smooth\n",
    "        game.make_action(actions[best_action_index])\n",
    "        #for _ in range(frame_repeat):\n",
    "        #    game.advance_action()\n",
    "\n",
    "    # Sleep between episodes\n",
    "    sleep(1.0)\n",
    "    score = game.get_total_reward()\n",
    "    print(\"Total score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n",
      "('Total score: ', -1.0)\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize the game with window visible\n",
    "game.set_window_visible(True)\n",
    "game.set_mode(Mode.ASYNC_PLAYER)\n",
    "game.init()\n",
    "\n",
    "for _ in range(episodes_to_watch):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        state = get_current_state()\n",
    "        state = state.view(1, 1, resolution[0], resolution[1])\n",
    "        best_action_index = get_action(state)\n",
    "\n",
    "        # Instead of make_action(a, frame_repeat) in order to make the animation smooth\n",
    "        game.make_action(actions[best_action_index])\n",
    "        #for _ in range(frame_repeat):\n",
    "        #    game.advance_action()\n",
    "\n",
    "    # Sleep between episodes\n",
    "    sleep(1.0)\n",
    "    score = game.get_total_reward()\n",
    "    print(\"Total score: \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
